---
title: "The state of AI discourse"
description: "It’s possible to believe AI is one of the most transformative tools of our time and that most of what’s being sold as AI is smoke and mirrors, or worse, complete bollocks. Both can be true."
pubDate: "04 Jun 2025 13:00:00"
---

For a while now, I've struggled to hold uncomfortable feelings about AI in tension with the reality of AI within our industry and world today. Thanks to a post by [Steve](https://steveklabnik.com/writing/i-am-disappointed-in-the-ai-discourse/), I feel compelled to try and articulate my current stance on the subject.

tl;dr:

> It’s possible to believe AI is one of the most transformative tools of our time and that most of what’s being sold as AI is smoke and mirrors, or worse, complete bollocks. Both can be true.

---

A familiar narrative has formed around AI in our industry, one that continues to divide creators in our space. Like Steve, I find myself disappointed, not in AI’s capabilities or potential, but in how we talk about it. The snake oil is easy to spot if you’re close to the tech, but harder for the average person wading through a timeline of grifters on LinkedIn. AI is a well established resident in the towerblock of technology, and will leave a lasting legacy on software engineering for years to come.

As always, there is a disconnect between the marketing hype and the technical reality that we as technologists are faced with.


## The expectation vs reality

One of the things that detracts from good discourse on AI is the involuntary reaction a lot of products have had to feeling the need to inject AI into every part of their product. Functionality that existed before the rise of AI reemerges as new functionality _now with 100% more AI_. A cunning move played by marketeers to demonstrate speed to market on meaningful functionality, but sadly one which is fooling no one.

NO> Using a hammer to saw a piece tends to do nothing more than make a mess.

Dunking on people or companies posting about AI may occasionally have merit, when there is clear exploitation or behaviour from bad actors going on, but try not to lose track of potentially interesting changes going on behind the scenes.

Meanwhile, skilled teams on the ground are actively trying to build meaningful products that solve real world problems.

We're seeing a record number of open source contributions emerge from AI innovation, often seeing real humans building new ways of doing things in the open for everyone to learn from. We're seeing real product teams sharing their process on how they're thoughtfully implementing AI functionality _because it makes sense to do so_, not because it's the latest hype.

We're seeing honest case studies of things that are proving this evolution of technology is more than just [web3](https://en.wikipedia.org/wiki/Web3) hype.

There is also the hugely important debate of creativity in our industry, and how there is pride and enjoyment our of the act of creating vs shipping lines of code (which in case you're new here, is never a good metric of productivity of value).


## A different engagement model

You can of course continue to ignore AI wholesale, I wouldn't blame you for that. That approach may, however, leave you open to blindspots as the future of our ecosystem takes shape. Whether you like it or not, it has already infiltrated our toolbelt, showing up in pretty much every software engineering tool there is to "help" you ship code. As always with tool diversification, there is a learning curve to figure out what is actually a useful augmentation of your creative process vs a complete blocker to getting things done.

So how could you think about what's going on with AI differently?

A good start is to **become more informed** about what's going on in AI. Challenge nonsense when you see it. This doesn't have to (and probably shouldn't) be in public. Challenging views that appeach to good to be true or present something as magical through your own research can only better your stance on something.

**Celebrate those in the community trying to harness a sustainable and effective future for AI.** There are teams of real people out there trying to make AI greener, ensure we act ethically with AI by introducing guardrails for how it behaves, and fighting the good fight to not _add AI to everything_, and those people need your support. Without those people we'll only be left with those who want to financially benefit from its existence as well as it's ability to exploit people and society as a whole.

Finally, try it. It's amazing how many people I've spoken to who are skeptical about AI only to come clean on the fact they've never used any of it and formed an opinion solely off things they've read on social media (which hopefully you don't need me to tell you is never a good thing). You should share your honest experiences of doing this. Found it sucked? Great! What sucked? Why? What can we learn from this?

As a standalone entity, AI isn’t a miracle or evil. It’s a tool. And like any tool, its impact will depend on how thoughtfully we use it, and how honestly we talk about it.

RESPONSIBILITY TO PRODUCE GOOD THINGS, LEARNING

## The invisibile impact

I believe AI can be transformative. But right now, we’re externalising too many of the costs. We’re burning compute, ignoring the human impact, and calling it progress.

We don’t get the benefits of AI for free. Every “magic” moment comes with a cost: energy, carbon, labour, or cognitive overhead—and most of us aren’t talking about that enough (or at all).

These important factors do need discussing within the context of other consumables, though. A resaonably new debate doing the rounds is the cost of energy and water usage by AI tooling against that of mass produced vegetables. While this is a good debate to have to provide a contrasting view on the general publics lack of awareness of how damaging it is to just eat well these days, they're not exactly equal in value. The counter argument to this is that you generally need to eat to stay alive, but we've all managed just fine without AI for centuries, blissfully unaware of the value a well crafted prompt could deliver to our lives.


	Environmental impact: massive data centre energy use, water consumption for cooling, carbon footprint of training/fine-tuning models.
	•	Labour exploitation: low-paid human annotators or content moderators.
	•	False sense of efficiency: risk of deskilling, over-automation, or removing nuance in decisions.
	•	Accessibility gap: concentration of AI power in a few companies or countries.



adoption curve/innovation curve

https://en.wikipedia.org/wiki/Diffusion_of_innovations

culture, laziness, thinking, learning, friction.


4. Reframe: These Aren’t AI Problems—They’re System Design Problems

This helps avoid fearmongering. You’re saying:
	•	These issues are design choices.
	•	We can do better by treating them as first-class engineering and policy concerns.

Example:

None of these tradeoffs are inevitable. But they are the result of how we’ve chosen to build, deploy, and monetise AI today.

5. Propose a Better Way

Frame what “better” looks like:
	•	Greener compute (e.g. choosing model size carefully, improving efficiency).
	•	Transparent sourcing of training data.
	•	Responsible governance and procurement.
	•	Valuing human judgment alongside automated tools.

Example:

The way forward isn’t to stop building AI. It’s to build like the cost matters. Like our systems should be sustainable, equitable, and useful—not just impressive.

6. Call to Action: Build With Integrity

Encourage your audience—especially tech leaders, builders, and buyers—to own their impact:
	•	Ask questions at work about environmental cost.
	•	Build tools with restraint, not just capability.
	•	Help shift the incentives from “bigger and faster” to “better and wiser.”

Example:

We need to make asking “at what cost?” a normal part of product planning. AI can still be part of a better future—but only if we treat its impact as part of the build, not a postscript.

## Think for yourself

Think deeper. Form an opinion. Don't be afraid to update it when new data comes to light.

If you're in the camp, how can I design this better, utilise this tech better to repay some of the debt mentioned above.

If you're yet to be convinced, read deeper than a thought leadership piece and form your own research. Understand how the latest models are built, deployed, marketed. Understand the approach to designing this tech to understand it better.


